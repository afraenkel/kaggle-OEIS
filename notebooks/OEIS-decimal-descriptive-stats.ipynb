{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src/py-oeis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oeis.etl.extract as extract\n",
    "import oeis.etl.features as feats\n",
    "import oeis.viz.plotting as plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = extract.load_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract.load_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poss_dec = (\n",
    "    features.loc[\n",
    "        (features.logmax <= 1.0) & \n",
    "        (features.nonneg == 1.0) & \n",
    "        (features.uniq == 10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_seq = {k:seqs[k] for k in poss_dec.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10502"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poss_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poss_dec.length.plot(kind='hist', bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10502.000000\n",
      "mean        99.747858\n",
      "std         10.871887\n",
      "min         10.000000\n",
      "25%         99.000000\n",
      "50%         99.000000\n",
      "75%        105.000000\n",
      "max        232.000000\n"
     ]
    }
   ],
   "source": [
    "print(poss_dec.length.describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 120\n",
    "for k, v in dec_seq.items():\n",
    "    d = (PAD - len(v))\n",
    "    if d >= 0:\n",
    "        dec_seq[k] = v + [np.NaN]*d\n",
    "    else:\n",
    "        dec_seq[k] = v[:PAD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = pd.DataFrame(dec_seq).T\n",
    "dec['tag'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dec = pd.DataFrame(np.random.randint(0,9, size=(len(dec), PAD)))\n",
    "rand_dec['tag'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([dec, rand_dec])\n",
    "X, y = data.drop('tag', axis=1).values, data.tag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim1, hidden_dim2, batch_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(1, hidden_dim1)\n",
    "        self.lstm2hidden = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.hidden2label = nn.Linear(hidden_dim2, 2)\n",
    "\n",
    "        self.hidden1 = self.init_hidden1()\n",
    "        self.hidden2 = self.init_hidden2()\n",
    "\n",
    "    def init_hidden1(self):\n",
    "        h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim1))\n",
    "        c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim1))\n",
    "        return (h0, c0)\n",
    "    \n",
    "    def init_hidden2(self):\n",
    "        h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim2))\n",
    "        c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim2))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        lstm_out, self.hidden1 = self.lstm(sequence, self.hidden1)\n",
    "        h = self.lstm2hidden(lstm_out[-1])\n",
    "        y  = self.hidden2label(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-656ac37eac1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-2b7e3abb410d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise RuntimeError(\n\u001b[1;32m    125\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 126\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 2\n",
    "sequence_len = PAD\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "batch_size = 5\n",
    "\n",
    "model = LSTMClassifier(hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, batch_size=batch_size)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "train_acc_ = []\n",
    "test_acc_ = []\n",
    "\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer = adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    for i, (seq, tag) in enumerate(zip(X_train.chunk(len(X_train)//5), y_train.chunk(len(y_train)//5))):\n",
    "        seq = Variable(seq)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        model.batch_size = len(tag)\n",
    "        model.hidden1 = model.init_hidden1()\n",
    "        model.hidden2 = model.init_hidden2()\n",
    "        output = model(seq.t())\n",
    "        \n",
    "        loss = loss_function(output, Variable(tag))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_acc += (predicted == tag).sum()\n",
    "        total += len(tag)\n",
    "        total_loss += loss.data[0]\n",
    "\n",
    "    train_loss_.append(total_loss / total)\n",
    "    train_acc_.append(total_acc / total)\n",
    "    \n",
    "#     ## testing epoch\n",
    "#     total_acc = 0.0\n",
    "#     total_loss = 0.0\n",
    "#     total = 0.0\n",
    "#     for i, (seq, tag) in enumerate(zip(X_test, y_test)):\n",
    "#         test_inputs, test_labels = testdata\n",
    "#         test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "#         if use_gpu:\n",
    "#             test_inputs, test_labels = Variable(test_inputs.cuda()), test_labels.cuda()\n",
    "#         else: test_inputs = Variable(test_inputs)\n",
    "\n",
    "#         model.batch_size = len(test_labels)\n",
    "#         model.hidden = model.init_hidden()\n",
    "#         output = model(test_inputs.t())\n",
    "\n",
    "#         loss = loss_function(output, Variable(test_labels))\n",
    "\n",
    "#         # calc testing acc\n",
    "#         _, predicted = torch.max(output.data, 1)\n",
    "#         total_acc += (predicted == test_labels).sum()\n",
    "#         total += len(test_labels)\n",
    "#         total_loss += loss.data[0]\n",
    "#     test_loss_.append(total_loss / total)\n",
    "#     test_acc_.append(total_acc / total)\n",
    "\n",
    "#     print('[Epoch: %3d/%3d] Training Loss: %.3f, Testing Loss: %.3f, Training Acc: %.3f, Testing Acc: %.3f'\n",
    "#           % (epoch, epochs, train_loss_[epoch], test_loss_[epoch], train_acc_[epoch], test_acc_[epoch]))\n",
    "\n",
    "param = {}\n",
    "param['lr'] = learning_rate\n",
    "param['batch size'] = batch_size\n",
    "param['embedding dim'] = embedding_dim\n",
    "param['hidden dim'] = hidden_dim\n",
    "param['sentence len'] = sentence_len\n",
    "\n",
    "result = {}\n",
    "result['train loss'] = train_loss_\n",
    "result['test loss'] = test_loss_\n",
    "result['train acc'] = train_acc_\n",
    "result['test acc'] = test_acc_\n",
    "result['param'] = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
